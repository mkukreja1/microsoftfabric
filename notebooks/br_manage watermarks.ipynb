{"cells":[{"cell_type":"code","source":["from delta.tables import *\n","# import datetime \n","import time\n","\n","# dt = str(datetime.date.today())\n","year, month, day = time.strftime(\"%Y\"), time.strftime(\"%m\"), time.strftime(\"%d\")\n","hour, minute, second = time.strftime(\"%H\"), time.strftime(\"%M\"), time.strftime(\"%S\")\n","\n","columns = [\"domain_name\", \"schema_name\", \"table_name\", \"incremental_column\", \"incremental_column_value\", \"merge_key_column\", \"delta_lakehouse_path\"]\n","values = [(\"sales\", \"dbo\", \"products\", \"updated_at\", \"1900-01-01 00:00:00.000\", \"product_code\",\"\"),\n","       (\"sales\", \"dbo\", \"store_customers\", \"updated_at\", \"1900-01-01 00:00:00.000\", \"customer_id\",\"\"),\n","       (\"sales\", \"dbo\", \"store_orders\", \"updated_at\", \"1900-01-01 00:00:00.000\", \"orders_number\",\"\"),\n","\t   (\"supply\", \"dbo\", \"inventory\", \"updated_at\", \"1900-01-01 00:00:00.000\", \"product\",\"\")]\n","\n","if not spark.catalog.tableExists(\"bronze_watermark_table\"):\n","    DeltaTable.createIfNotExists(spark) \\\n","        .tableName(\"bronze_watermark_table\") \\\n","        .addColumn(\"domain_name\", \"STRING\") \\\n","        .addColumn(\"schema_name\", \"STRING\") \\\n","        .addColumn(\"table_name\", \"STRING\") \\\n","        .addColumn(\"incremental_column\", \"STRING\") \\\n","        .addColumn(\"incremental_column_value\", \"TIMESTAMP\", comment = \"updated on each run\") \\\n","        .addColumn(\"merge_key_column\", \"STRING\") \\\n","        .addColumn(\"delta_lakehouse_path\", \"STRING\", comment = \"updated on each run\") \\\n","        .execute()\n","        \n","    df = spark.createDataFrame(values, columns)\n","    df = df.withColumn(\"incremental_column_value\",df.incremental_column_value.cast(\"timestamp\"))\n","    df.write.mode(\"append\").format(\"delta\").saveAsTable(\"bronze_watermark_table\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"e61256f5-6ff5-416d-8911-d3957737116e"},{"cell_type":"code","source":["def get_tables_list():\n","    _df = spark.read.table(\"bronze_watermark_table\")\n","    display(_df)\n","    tbls = _df.select(\"table_name\", \"domain_name\").collect()\n","\n","    return tbls\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"85fb2278-2907-4ebb-9424-10ddfe5f3c2b"},{"cell_type":"code","source":["def create_and_update_delta_source_path(_domain_name, _table, _year, _month, _day, _hour):\n","    folder = f\"bronze/{_domain_name}/{_table}/{_year}/{_month}/{_day}/{_hour}\"\n","    path = f\"Files/{folder}\"\n","   \n","    try:\n","        if not mssparkutils.fs.exists(path):\n","            print(f\"path does not exit, creating path: {path}\")\n","            mssparkutils.fs.mkdirs(path)\n","        else:\n","            print(f\"path: {path} already exists\")\n","    except Exception as e:\n","        print(e)\n","   \n","    query = f\"UPDATE bronze_watermark_table SET delta_lakehouse_path = '{folder}' WHERE table_name = '{_table}'\"\n","    spark.sql(query)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1c7a54e2-9ebf-47ab-8198-9ebe5d8c40bc"},{"cell_type":"code","source":["tables_to_process = get_tables_list()\n","for row in tables_to_process:\n","    table = row[\"table_name\"]\n","    domain_name = row[\"domain_name\"]\n","    create_and_update_delta_source_path(domain_name, table, year, month, day, hour)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"89c1a120-2ad1-42c9-8a7c-50abb6d5ed63"},{"cell_type":"code","source":["%%sql\n","\n","SELECT table_name, delta_lakehouse_path FROM bronze_watermark_table\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"c07ab3f9-e764-4143-84d4-936a9d9ba65f"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"7381f5b4-a268-4521-ac70-e813ffe12dbb","default_lakehouse_name":"Electroniz_Lakehouse","default_lakehouse_workspace_id":"9ac8702b-7d23-461d-b816-aad5ed11c9b0"}}},"nbformat":4,"nbformat_minor":5}